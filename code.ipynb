{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#others\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#retrieving data\n",
    "import requests\n",
    "import json\n",
    "\n",
    "#plotting\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from ipywidgets import interact, fixed, IntSlider\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#optimization\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retrieve data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading data from coingecko.com\n",
    "def download_historical_data(crypto_id, days):\n",
    "    url = f'https://api.coingecko.com/api/v3/coins/{crypto_id}/market_chart'\n",
    "\n",
    "    # Set the number of days for historical data\n",
    "    params = {\n",
    "        'vs_currency': 'usd',\n",
    "        'days': days\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params, headers=headers)\n",
    "        data = response.json()\n",
    "\n",
    "        # Save the data to a json file\n",
    "        filename = f'{crypto_id}_historical_data.json'\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(data, f)\n",
    "\n",
    "        print(f\"Downloaded historical data for {crypto_id} successfully and saved to {filename}!\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error occurred while downloading data for {crypto_id}: {e}\")\n",
    "\n",
    "# Specify the crypto IDs and the number of days of historical data you want to download\n",
    "crypto_ids = ['bitcoin', 'ethereum', 'litecoin', 'dogecoin', 'vechain', 'filecoin', 'binancecoin', 'cardano', 'ripple', 'polkadot']\n",
    "days = 365\n",
    "\n",
    "# Iterate through the list of crypto IDs and download the data\n",
    "for crypto_id in crypto_ids:\n",
    "    download_historical_data(crypto_id, days)\n",
    "    \n",
    "dfs = []  # List to store individual DataFrames\n",
    "\n",
    "for crypto_id in crypto_ids:\n",
    "    # Load the JSON file\n",
    "    filename = f'{crypto_id}_historical_data.json'\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract the price data from the JSON structure\n",
    "    prices = data['prices']\n",
    "\n",
    "    # Create a Pandas DataFrame\n",
    "    df = pd.DataFrame(prices, columns=['Timestamp', f'{crypto_id}_Price'])\n",
    "\n",
    "    # Convert the timestamp to datetime\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='ms')\n",
    "\n",
    "    # Round down the timestamp to the nearest day\n",
    "    df['Timestamp'] = df['Timestamp'].dt.floor('D')\n",
    "\n",
    "    # Group by timestamp and take the mean of prices\n",
    "    df = df.groupby('Timestamp').mean()\n",
    "\n",
    "    # Add the DataFrame to the list\n",
    "    dfs.append(df)\n",
    "\n",
    "# Merge all the DataFrames into a single DataFrame based on the Timestamp index\n",
    "indices = pd.concat(dfs, axis=1)\n",
    "\n",
    "# Print the merged DataFrame\n",
    "indices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices.isna().sum()\n",
    "#There is no missing in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle outliers by winsorizing at 5% and 95% percentiles\n",
    "pct_low, pct_high = 0.05, 0.95\n",
    "indices = indices.apply(lambda x: np.clip(x, x.quantile(pct_low), x.quantile(pct_high)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation of the daily and cumulative returns for each asset\n",
    "returns = indices.pct_change().dropna()\n",
    "cum_returns = returns.add(1).cumprod().sub(1).dropna()*100\n",
    "\n",
    "#plotting Cumulative returns\n",
    "fig = px.line(cum_returns, x=cum_returns.index, y=cum_returns.columns, title='Cumulative Returns of Indices 1Y')\n",
    "fig.update_xaxes(title_text='Date')\n",
    "fig.update_yaxes(title_text='Cumulative Return in %')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation rolling volatility for each asset\n",
    "window_size = 7  # Specify the window size for the rolling calculation\n",
    "volatility = returns.rolling(window=window_size).std()\n",
    "\n",
    "#plotting volatility\n",
    "fig = px.line(volatility, x=cum_returns.index, y=cum_returns.columns, title='Volatility of Indices 1Y')\n",
    "fig.update_xaxes(title_text='Date')\n",
    "fig.update_yaxes(title_text='Volatility')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementing models and evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximum_sharpe_ratio_portfolio(returns, allow_shorting=True):\n",
    "    num_assets = returns.shape[1]\n",
    "    \n",
    "    # Define the objective function for maximum Sharpe ratio portfolio\n",
    "    def objective_function(weights):\n",
    "        # Calculate portfolio mean return\n",
    "        mean_returns = returns.mean()        \n",
    "        # Calculate portfolio variance-covariance matrix\n",
    "        covariance_matrix = returns.cov()\n",
    "        # Calculate portfolio return and variance\n",
    "        portfolio_mean = np.sum(mean_returns*weights)\n",
    "        portfolio_std = np.sqrt(np.dot(weights.T, np.dot(covariance_matrix, weights)))        \n",
    "        # Calculate ratio\n",
    "        sharpe_ratio = portfolio_mean / portfolio_std\n",
    "        return -sharpe_ratio\n",
    "    \n",
    "    # Define the constraints\n",
    "    constraints = ({'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1.0})\n",
    "    \n",
    "    if allow_shorting:\n",
    "        bounds = [(None, None)] * num_assets  # No bounds on weights\n",
    "    else:\n",
    "        bounds = [(0, None)] * num_assets  # No shorting allowed\n",
    "    \n",
    "    # Perform the optimization\n",
    "    initial_weights = np.ones(num_assets) / num_assets  # Start with equal weights\n",
    "    optimized_weights = minimize(objective_function, initial_weights, bounds=bounds, constraints=constraints, method='SLSQP').x\n",
    "    return optimized_weights\n",
    "\n",
    "def minimum_variance_portfolio(returns, allow_shorting=True):\n",
    "    num_assets = returns.shape[1]\n",
    "\n",
    "    def objective_function(weights):\n",
    "        mean_returns = returns.mean()\n",
    "        covariance_matrix = returns.cov()\n",
    "        portfolio_mean = np.sum(mean_returns*weights)\n",
    "        portfolio_variance = np.sqrt(np.dot(weights.T, np.dot(covariance_matrix, weights)))\n",
    "        return portfolio_variance\n",
    "    \n",
    "    constraints = ({'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1.0})\n",
    "    \n",
    "    if allow_shorting:\n",
    "        bounds = [(None, None)] * num_assets\n",
    "    else:\n",
    "        bounds = [(0, None)] * num_assets\n",
    "    \n",
    "    initial_weights = np.ones(num_assets) / num_assets\n",
    "    optimized_weights = minimize(objective_function, initial_weights, bounds=bounds, constraints=constraints, method='SLSQP').x\n",
    "    return optimized_weights\n",
    "\n",
    "\n",
    "# Portfolio Performance Evaluation\n",
    "def evaluate_portfolio(returns, weights, rebalancing_frequency='daily'):\n",
    "    n = len(returns)\n",
    "    if rebalancing_frequency == 'daily':\n",
    "        returns_rebalanced = returns\n",
    "    elif rebalancing_frequency == 'weekly':\n",
    "        returns_rebalanced = returns[::7]\n",
    "    elif rebalancing_frequency == 'monthly':\n",
    "        returns_rebalanced = returns[::30]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid rebalancing frequency. Choose from 'daily', 'weekly', or 'monthly'.\")\n",
    "    \n",
    "    portfolio_returns = np.dot(returns_rebalanced, weights)\n",
    "    portfolio_cumulative_returns = np.cumprod(portfolio_returns + 1) - 1\n",
    "    \n",
    "    portfolio_stats = {\n",
    "        'Expected Return': np.mean(portfolio_returns),\n",
    "        'Volatility': np.std(portfolio_returns),\n",
    "        'Sharpe Ratio': np.mean(portfolio_returns) / np.std(portfolio_returns),\n",
    "        'Cumulative Returns': portfolio_cumulative_returns[-1]\n",
    "    }\n",
    "    \n",
    "    return portfolio_stats, portfolio_cumulative_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute daily, weekly, and monthly rebalanced portfolios\n",
    "rebalancing_rules = ['daily', 'weekly', 'monthly']\n",
    "portfolio_optimization_models = [minimum_variance_portfolio, maximum_sharpe_ratio_portfolio]\n",
    "\n",
    "for rebalancing_rule in rebalancing_rules:\n",
    "    for optimization_model in portfolio_optimization_models:\n",
    "        # Calculate portfolio weights\n",
    "        weights = optimization_model(returns, allow_shorting=False)\n",
    "        # Evaluate portfolio performance\n",
    "        stats, cumulative_returns = evaluate_portfolio(returns, weights, rebalancing_frequency=rebalancing_rule)\n",
    "        # Calculate asset allocation\n",
    "        allocation = pd.DataFrame(np.round(weights*100,4),index=returns.columns,columns=['allocation'])\n",
    "        allocation['allocation'] = allocation['allocation'].map('{:.1f}%'.format)\n",
    "        # Print portfolio statistics\n",
    "        print(f\"Rebalancing rule: {rebalancing_rule}\")\n",
    "        print(f\"Optimization model: {optimization_model.__name__}\")\n",
    "        print(f\"Assets:\")\n",
    "        print(allocation.to_string(header=False))\n",
    "        print(f\"Expected returns: {round(stats['Expected Return'],4)}\")\n",
    "        print(f\"Cumulative returns: {round(stats['Cumulative Returns'],4)}\")\n",
    "        print(f\"Volatility: {round(stats['Volatility'],4)}\")\n",
    "        print(f\"Sharpe ratio: {round(stats['Sharpe Ratio'],4)}\")\n",
    "       # Plot cumulative returns\n",
    "        if rebalancing_rule == 'daily':\n",
    "            fig = px.line(cumulative_returns, x=cum_returns.index, y=cumulative_returns, title='Cumulative Returns of Indices 1Y')\n",
    "        elif rebalancing_rule == 'weekly':\n",
    "            fig = px.line(cumulative_returns, x=cum_returns.index[::7], y=cumulative_returns, title='Cumulative Returns of Indices 1Y')\n",
    "        elif rebalancing_rule == 'monthly':\n",
    "            fig = px.line(cumulative_returns, x=cum_returns.index[::30], y=cumulative_returns, title='Cumulative Returns of Indices 1Y')\n",
    "        else:\n",
    "            raise ValueError(\"Invalid rebalancing frequency. Choose from 'daily', 'weekly', or 'monthly'.\")\n",
    "        fig.update_xaxes(title_text='Date')\n",
    "        fig.update_yaxes(title_text='Cumulative Return in %')\n",
    "        fig.show()\n",
    "        print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_performance(weights, mean_returns, cov_matrix):\n",
    "    \"\"\"\n",
    "    Calculates the portfolio's standard deviation and annualized return.\n",
    "    \n",
    "    Args:\n",
    "        weights (np.ndarray): Array of portfolio weights.\n",
    "        mean_returns (pd.Series): Series of mean returns for each asset.\n",
    "        cov_matrix (pd.DataFrame): Covariance matrix of asset returns.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple: Standard deviation and annualized return of the portfolio.\n",
    "    \"\"\"\n",
    "    returns = np.sum(mean_returns*weights)*365\n",
    "    std = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))*np.sqrt(365)\n",
    "    return std, returns\n",
    "\n",
    "def random_portfolios(num_portfolios, mean_returns, cov_matrix):\n",
    "    \"\"\"\n",
    "    Generates random portfolios with given number of portfolios and asset information.\n",
    "    \n",
    "    Args:\n",
    "        num_portfolios (int): Number of random portfolios to generate.\n",
    "        mean_returns (pd.Series): Series of mean returns for each asset.\n",
    "        cov_matrix (pd.DataFrame): Covariance matrix of asset returns.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple: Array of portfolio standard deviations, returns, and Sharpe ratios, and a list of portfolio weights.\n",
    "    \"\"\"\n",
    "    results = np.zeros((3,num_portfolios))\n",
    "    weights_record = []\n",
    "    \n",
    "    num_assets = len(mean_returns)\n",
    "    \n",
    "    for i in range(num_portfolios):\n",
    "        weights = np.random.random(num_assets)\n",
    "        weights /= np.sum(weights)\n",
    "        weights_record.append(weights)\n",
    "        portfolio_std_dev, portfolio_return = portfolio_performance(weights, mean_returns, cov_matrix)\n",
    "        results[0,i] = portfolio_std_dev\n",
    "        results[1,i] = portfolio_return\n",
    "        results[2,i] = portfolio_return / portfolio_std_dev\n",
    "    \n",
    "    return results, weights_record\n",
    "\n",
    "def efficient_return(mean_returns, cov_matrix, target):\n",
    "    \"\"\"\n",
    "    Finds the weights for an efficient portfolio given a target return.\n",
    "    \n",
    "    Args:\n",
    "        mean_returns (pd.Series): Series of mean returns for each asset.\n",
    "        cov_matrix (pd.DataFrame): Covariance matrix of asset returns.\n",
    "        target (float): Target portfolio return.\n",
    "    \n",
    "    Returns:\n",
    "        scipy.optimize.OptimizeResult: Result of the optimization with the weights for the efficient portfolio.\n",
    "    \"\"\"\n",
    "    num_assets = len(mean_returns)\n",
    "    args = (mean_returns, cov_matrix)\n",
    "\n",
    "    def portfolio_return(weights):\n",
    "        return portfolio_performance(weights, mean_returns, cov_matrix)[1]\n",
    "    \n",
    "    def portfolio_volatility(weights, mean_returns, cov_matrix):\n",
    "        return portfolio_performance(weights, mean_returns, cov_matrix)[0]\n",
    "\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: portfolio_return(x) - target},\n",
    "                   {'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bounds = tuple((0,1) for asset in range(num_assets))\n",
    "    result = minimize(portfolio_volatility, num_assets*[1./num_assets,], args=args, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    return result\n",
    "\n",
    "def efficient_frontier(mean_returns, cov_matrix, returns_range):\n",
    "    \"\"\"\n",
    "    Generates a list of efficient portfolios along the efficient frontier.\n",
    "    \n",
    "    Args:\n",
    "        mean_returns (pd.Series): Series of mean returns for each asset.\n",
    "        cov_matrix (pd.DataFrame): Covariance matrix of asset returns.\n",
    "        returns_range (np.ndarray): Array of target returns.\n",
    "    \n",
    "    Returns:\n",
    "        List: List of OptimizeResult objects representing the efficient portfolios.\n",
    "    \"\"\"\n",
    "    efficients = []\n",
    "    for ret in returns_range:\n",
    "        efficients.append(efficient_return(mean_returns, cov_matrix, ret))\n",
    "    return efficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_calculated_ef_with_random(returns, portfolio_optimization_models, num_portfolios=10000, interactive=False):\n",
    "    num_assets = returns.shape[1]\n",
    "    # Calculate portfolio mean return\n",
    "    mean_returns = returns.mean()\n",
    "    # Calculate portfolio variance-covariance matrix\n",
    "    covariance_matrix = returns.cov()\n",
    "    def plot_efficient_frontier(num_portfolios):\n",
    "        # Generate random portfolios\n",
    "        results, _ = random_portfolios(num_portfolios, mean_returns, covariance_matrix)\n",
    "        results=pd.DataFrame(results).T\n",
    "        results = results.rename(columns={2: 'Sharpe Ratio'})\n",
    "        # Plot scatter plot of random portfolios\n",
    "        fig = px.scatter(results, x=0, y=1, color='Sharpe Ratio', color_continuous_scale='YlGnBu', opacity=0.3,\n",
    "                         labels={0: 'Volatility', 1: 'Returns'})\n",
    "        # Plot optimized portfolios\n",
    "        for optimization_model in portfolio_optimization_models:\n",
    "            weights = optimization_model(returns, allow_shorting=False)\n",
    "            sdp, rp = portfolio_performance(weights, mean_returns, covariance_matrix)\n",
    "            fig.add_trace(go.Scatter(x=[sdp], y=[rp], mode='markers', name=optimization_model.__name__))\n",
    "        # Plot efficient frontier\n",
    "        target = np.linspace(0, 0.65, 50)\n",
    "        efficient_portfolios = efficient_frontier(mean_returns, covariance_matrix, target)\n",
    "        fig.add_trace(go.Scatter(x=[p['fun'] for p in efficient_portfolios], y=target,\n",
    "                                 mode='lines', line=dict(dash='dash'), name='Efficient Frontier'))\n",
    "        # Update layout and display the plot\n",
    "        fig.update_layout(title='Calculated Portfolio Optimization based on Efficient Frontier',\n",
    "                          xaxis_title='Volatility (annualized)', yaxis_title='Returns (annualized)', showlegend=True)\n",
    "        fig.update_layout(legend=dict(x=0, y=1, traceorder='normal', font=dict(size=12), bgcolor='LightSteelBlue', bordercolor='Black', borderwidth=2))\n",
    "        fig.show()\n",
    "    # Create interactive widget\n",
    "    if interactive:\n",
    "        interact(plot_efficient_frontier, num_portfolios=IntSlider(min=10000, max=100000, step=10000, continuous_update=False))\n",
    "    else:\n",
    "        return plot_efficient_frontier(num_portfolios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_calculated_ef_with_random(returns, portfolio_optimization_models, num_portfolios=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_calculated_ef_with_random(returns, portfolio_optimization_models,  num_portfolios=10000, interactive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q-learning algorithm for automated stock trading - additional part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import random\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, state_size, window_size, trend, skip, batch_size):\n",
    "        # Initialize the Agent object with necessary attributes\n",
    "        self.state_size = state_size\n",
    "        self.window_size = window_size\n",
    "        self.half_window = window_size // 2\n",
    "        self.trend = trend\n",
    "        self.skip = skip\n",
    "        self.action_size = 3\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = deque(maxlen=1000)\n",
    "        self.inventory = []\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 0.5\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.999\n",
    "        \n",
    "        # TensorFlow graph setup\n",
    "        tf.reset_default_graph()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.X = tf.placeholder(tf.float32, [None, self.state_size])\n",
    "        self.Y = tf.placeholder(tf.float32, [None, self.action_size])\n",
    "        feed = tf.layers.dense(self.X, 256, activation=tf.nn.relu)\n",
    "        self.logits = tf.layers.dense(feed, self.action_size)\n",
    "        self.cost = tf.reduce_mean(tf.square(self.Y - self.logits))\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(1e-5).minimize(self.cost)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def act(self, state):\n",
    "        # Choose an action based on the current state\n",
    "        if random.random() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        return np.argmax(self.sess.run(self.logits, feed_dict={self.X: state})[0])\n",
    "    \n",
    "    def get_state(self, t):\n",
    "        # Generate the state representation for a given time step\n",
    "        window_size = self.window_size + 1\n",
    "        d = t - window_size + 1\n",
    "        block = self.trend[d : t + 1] if d >= 0 else -d * [self.trend[0]] + self.trend[0 : t + 1]\n",
    "        res = []\n",
    "        for i in range(window_size - 1):\n",
    "            res.append(block[i + 1] - block[i])\n",
    "        return np.array([res])\n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        # Replay memory to train the agent\n",
    "        mini_batch = []\n",
    "        l = len(self.memory)\n",
    "        for i in range(l - batch_size, l):\n",
    "            mini_batch.append(self.memory[i])\n",
    "        replay_size = len(mini_batch)\n",
    "        X = np.empty((replay_size, self.state_size))\n",
    "        Y = np.empty((replay_size, self.action_size))\n",
    "        states = np.array([a[0][0] for a in mini_batch])\n",
    "        new_states = np.array([a[3][0] for a in mini_batch])\n",
    "        Q = self.sess.run(self.logits, feed_dict={self.X: states})\n",
    "        Q_new = self.sess.run(self.logits, feed_dict={self.X: new_states})\n",
    "        for i in range(len(mini_batch)):\n",
    "            state, action, reward, next_state, done = mini_batch[i]\n",
    "            target = Q[i]\n",
    "            target[action] = reward\n",
    "            if not done:\n",
    "                target[action] += self.gamma * np.amax(Q_new[i])\n",
    "            X[i] = state\n",
    "            Y[i] = target\n",
    "        cost, _ = self.sess.run([self.cost, self.optimizer], feed_dict={self.X: X, self.Y: Y})\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        return cost\n",
    "    \n",
    "    def buy(self, initial_money):\n",
    "        # Buy/sell actions based on the current state and available money\n",
    "        starting_money = initial_money\n",
    "        states_sell = []\n",
    "        states_buy = []\n",
    "        inventory = []\n",
    "        state = self.get_state(0)\n",
    "        for t in range(0, len(self.trend) - 1, self.skip):\n",
    "            action = self.act(state)\n",
    "            next_state = self.get_state(t + 1)\n",
    "            if action == 1 and initial_money >= self.trend[t] and t < (len(self.trend) - self.half_window):\n",
    "                inventory.append(self.trend[t])\n",
    "                initial_money -= self.trend[t]\n",
    "                states_buy.append(t)\n",
    "                print('day %d: buy 1 unit at price %f, total balance %f' % (t, self.trend[t], initial_money))\n",
    "            elif action == 2 and len(inventory):\n",
    "                bought_price = inventory.pop(0)\n",
    "                initial_money += self.trend[t]\n",
    "                states_sell.append(t)\n",
    "                try:\n",
    "                    invest = ((self.trend[t] - bought_price) / bought_price) * 100\n",
    "                except:\n",
    "                    invest = 0\n",
    "                print(\n",
    "                    'day %d, sell 1 unit at price %f, total balance %f'\n",
    "                    % (t, self.trend[t], initial_money)\n",
    "                )\n",
    "            state = next_state\n",
    "        invest = ((initial_money - starting_money) / starting_money) * 100\n",
    "        total_gains = initial_money - starting_money\n",
    "        return states_buy, states_sell, total_gains, invest\n",
    "    \n",
    "    def train(self, iterations, checkpoint, initial_money):\n",
    "        # Train the agent for a certain number of iterations\n",
    "        for i in range(iterations):\n",
    "            total_profit = 0\n",
    "            inventory = []\n",
    "            state = self.get_state(0)\n",
    "            starting_money = initial_money\n",
    "            for t in range(0, len(self.trend) - 1, self.skip):\n",
    "                action = self.act(state)\n",
    "                next_state = self.get_state(t + 1)\n",
    "                if action == 1 and starting_money >= self.trend[t] and t < (len(self.trend) - self.half_window):\n",
    "                    inventory.append(self.trend[t])\n",
    "                    starting_money -= self.trend[t]\n",
    "                elif action == 2 and len(inventory) > 0:\n",
    "                    bought_price = inventory.pop(0)\n",
    "                    total_profit += self.trend[t] - bought_price\n",
    "                    starting_money += self.trend[t]\n",
    "                invest = ((starting_money - initial_money) / initial_money)\n",
    "                self.memory.append(\n",
    "                    (state, action, invest, next_state, starting_money < initial_money)\n",
    "                )\n",
    "                state = next_state\n",
    "                batch_size = min(self.batch_size, len(self.memory))\n",
    "                cost = self.replay(batch_size)\n",
    "            if (i + 1) % checkpoint == 0:\n",
    "                print(\n",
    "                    'epoch: %d, reward: %f.3, loss: %f'\n",
    "                    % (i + 1, total_profit, cost)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_crypto = ['litecoin_Price', 'vechain_Price', 'filecoin_Price']\n",
    "\n",
    "#initialization\n",
    "initial_money = 100000\n",
    "window_size = 30\n",
    "skip = 1\n",
    "batch_size = 32\n",
    "\n",
    "for crypto_id in chosen_crypto:\n",
    "    #df of crypto chosen\n",
    "    df = indices[crypto_id].values.tolist()\n",
    "    #defining agent\n",
    "    agent = Agent(state_size = window_size, \n",
    "              window_size = window_size, \n",
    "              trend = df, \n",
    "              skip = skip, \n",
    "              batch_size = batch_size)\n",
    "    #training\n",
    "    agent.train(iterations = 100, checkpoint = 10, initial_money = initial_money)\n",
    "    states_buy, states_sell, total_gains, invest = agent.buy(initial_money = initial_money)\n",
    "    #plotting results\n",
    "    fig = plt.figure(figsize = (15,5))\n",
    "    plt.plot(df, color='r', lw=2.)\n",
    "    plt.plot(df, '^', markersize=10, color='m', label = 'buying signal', markevery = states_buy)\n",
    "    plt.plot(df, 'v', markersize=10, color='k', label = 'selling signal', markevery = states_sell)\n",
    "    plt.title(f'Buy/sell for {crypto_id} - at the end number of coins: %d, value of coins: %.2f, balance: %.2f, total gain: %.2f' % (len(states_buy) - len(states_sell), round((len(states_buy) - len(states_sell)) * indices['litecoin_Price'][-1], 2), initial_money + total_gains, round((len(states_buy) - len(states_sell)) * indices['litecoin_Price'][-1] + total_gains, 2)))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
